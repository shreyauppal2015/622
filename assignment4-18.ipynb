{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74ecb8a67a89035a4e3000cf9476beac",
     "grade": false,
     "grade_id": "cell-a23b14ebbe230e18",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Information Visualization II\n",
    "\n",
    "## School of Information, University of Michigan\n",
    "\n",
    "## Week 4:\n",
    "\n",
    "- Text visualizations\n",
    "\n",
    "## Assignment Overview\n",
    "### The objectives for this week are for you to:\n",
    "\n",
    "- Understand how to model a corpus using statistical and visual techniques\n",
    "- Construct an interactive information visualization for search tasks\n",
    "\n",
    "### The total score of this assignment will be\n",
    "- Problem 1 (20 points)\n",
    "- Problem 2 (80 points)\n",
    "\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- We have created two textual datasets for you. One contains the text from Wikipedia pages related to data mining (algorithms, software, techniques, people, etc.). The second is related to *real* mining (equipment, companies, locations, etc.). \n",
    "\n",
    "### Important notes:\n",
    "1) Grading for this assignment is entirely done by manual inspection. You will have lots of control over the look and feel of problem 2.\n",
    "\n",
    "2) When turning in your PDF, please use the File -> Print -> Save as PDF option ***from your browser***. Do ***not*** use the File->Download as->PDF option. Complete instructions for this are under Resources in the Coursera page for this class.\n",
    "\n",
    "If you're having trouble with printing, take a look at [this video](https://youtu.be/PiO-K7AoWjk).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import spacy\n",
    "import math\n",
    "import numpy as np\n",
    "import scattertext as st\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from datetime import datetime\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility classes that will help us load the data in\n",
    "def lemmatize(instring,title=\"\",lemmaCache = {}):\n",
    "    parsed = None\n",
    "    \n",
    "    if ((title != \"\") & (title in lemmaCache)):\n",
    "        parsed = lemmaCache[title]    \n",
    "    else:\n",
    "        parsed = sp(instring)\n",
    "\n",
    "    if (lemmaCache != None):\n",
    "        lemmaCache[title] = parsed\n",
    "    sent = [x.text if (x.lemma_ == \"-PRON-\") else x.lemma_ for x in parsed]\n",
    "    return(sent)\n",
    "\n",
    "def generateData(filepath,lemmaCache=None):\n",
    "    articles = []\n",
    "    with open(filepath) as fp:\n",
    "        for docid, line in enumerate(fp):\n",
    "            doc = json.loads(line)\n",
    "            doclines = doc['text'].split(\"\\n\\n\")\n",
    "            ilineid = -1  # we're going to replace the original lineids so there are no gaps\n",
    "            for lineid,docline in enumerate(doclines):\n",
    "                obj = {}\n",
    "                obj['docid'] = docid;\n",
    "                obj['title'] = doc['title']\n",
    "                paraterms = lemmatize(docline,doc['title']+str(lineid),lemmaCache)\n",
    "                obj['text'] = ' ' + ' '.join(paraterms) + ' '\n",
    "                obj['tokencount'] = len(paraterms)\n",
    "                if ('category' in doc):\n",
    "                    obj['category'] = doc['category']\n",
    "                if (len(paraterms) > 10):\n",
    "                    ilineid = ilineid + 1\n",
    "                    obj['lineid'] = ilineid\n",
    "                    articles.append(obj)\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "def loadFile(classname,classpath,maxc=200,lemmaCache={}):\n",
    "    articles = []\n",
    "    with open(classpath) as fp:\n",
    "        for docid, line in enumerate(fp):\n",
    "            doc = json.loads(line)\n",
    "            doclines = doc['text'].split(\"\\n\\n\")\n",
    "            obj = {}\n",
    "            obj['docid'] = docid;\n",
    "            obj['title'] = doc['title']\n",
    "            paraterms = lemmatize(doc['text'],doc['title'],lemmaCache)\n",
    "            obj['text'] = ' ' + ' '.join(paraterms) + ' '\n",
    "            obj['label'] = classname\n",
    "            if ('category' in doc):\n",
    "                obj['category'] = doc['category']\n",
    "            if (len(paraterms) > 10):\n",
    "                articles.append(obj)\n",
    "            if (docid > maxc):\n",
    "                break\n",
    "    return(articles)\n",
    "\n",
    "def loadClasses(class1name,class1path,class2name,class2path,maxc=300):\n",
    "    articles = loadFile(class1name,class1path) + loadFile(class2name,class2path)\n",
    "    return pd.DataFrame(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enable correct rendering\n",
    "alt.renderers.enable('default')\n",
    "\n",
    "# uses intermediate json files to speed things up\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "614dc7e661bce8693b374a1a57a6f719",
     "grade": false,
     "grade_id": "cell-1e49deb9034c21c1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Before we start...\n",
    "\n",
    "We have created a function for you called ```lemmatize(...)```. It takes as input a string and assumes that spaces are token delimiters. For each token/word, the system will lowercase it, stem it (getting the root), and generally clean it up.  The data we load from our files undergoes the same transformation. So it's important to lemmatize your terms if you are looking them up. For example, you won't find the word \"data\" in the DataFrame. All instances get transformed to \"datum.\" Thus, it's important to remember to do this transformation. Note, however, that if you query for \"Data Mining\" (in capitals), the system assumes that this is a name, and will not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized version of 'data mining' is: ['data', 'mining']\n",
      "The lemmatized version of 'Data Mining' is: ['Data', 'Mining']\n",
      "The lemmatized version of 'executing awesome algorithms' is: ['execute', 'awesome', 'algorithm']\n",
      "The lemmatized version of 'Data mining algorithms are super exciting.' is: ['data', 'mining', 'algorithm', 'be', 'super', 'exciting', '.']\n"
     ]
    }
   ],
   "source": [
    "# here's a few examples\n",
    "\n",
    "query1 = \"data mining\"\n",
    "print(\"The lemmatized version of '\"+query1+\"' is:\", lemmatize(query1))\n",
    "\n",
    "query2 = \"Data Mining\"  # proper name (like a business)\n",
    "print(\"The lemmatized version of '\"+query2+\"' is:\", lemmatize(query2))\n",
    "\n",
    "query3 = \"executing awesome algorithms\"\n",
    "print(\"The lemmatized version of '\"+query3+\"' is:\", lemmatize(query3))\n",
    "\n",
    "query4 = \"Data mining algorithms are super exciting.\"\n",
    "print(\"The lemmatized version of '\"+query4+\"' is:\", lemmatize(query4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3930089745fdbb105f08345ba29d83f",
     "grade": false,
     "grade_id": "cell-980fb7d6b73f6dc8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Problem 1 (20 points)\n",
    "\n",
    "For this first problem, we will be comparing which terms most often appear in which of our two corpora: 'data' mining and 'real' mining.\n",
    "\n",
    "![\"mining v mining](assets/miningvsmining.png)\n",
    "\n",
    "Let's load the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will load the two files and label them with one of the two class labels\n",
    "# lemmatizing these files takes some time on Coursera so we've pre-calculated it for you.\n",
    "# If you want to run this process, uncomment the next two lines of code\n",
    "# miningdf = loadClasses('data mining','assets/mlarticles.jsonl','real mining','assets/miningarticles.jsonl')\n",
    "# miningdf.to_csv(\"assets/miningvmining.csv\",index=False)\n",
    "\n",
    "# load from cached file\n",
    "miningdf = pd.read_csv(\"assets/miningvmining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Statistical learning theory</td>\n",
       "      <td>statistical learning theory be a framework fo...</td>\n",
       "      <td>data mining</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>Ocean Data View</td>\n",
       "      <td>ocean data view ( odv ) be a proprietary , fr...</td>\n",
       "      <td>data mining</td>\n",
       "      <td>Data analysis software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>PowerLab</td>\n",
       "      <td>powerlab ( before 1998 be refer to as maclab ...</td>\n",
       "      <td>data mining</td>\n",
       "      <td>Data analysis software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>Offline learning</td>\n",
       "      <td>in machine learning , system which employ off...</td>\n",
       "      <td>data mining</td>\n",
       "      <td>Machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>90</td>\n",
       "      <td>Lutterade</td>\n",
       "      <td>lutterade be a district of geleen and later s...</td>\n",
       "      <td>real mining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     docid                        title  \\\n",
       "38      38  Statistical learning theory   \n",
       "165    165              Ocean Data View   \n",
       "170    170                     PowerLab   \n",
       "127    127             Offline learning   \n",
       "292     90                    Lutterade   \n",
       "\n",
       "                                                  text        label  \\\n",
       "38    statistical learning theory be a framework fo...  data mining   \n",
       "165   ocean data view ( odv ) be a proprietary , fr...  data mining   \n",
       "170   powerlab ( before 1998 be refer to as maclab ...  data mining   \n",
       "127   in machine learning , system which employ off...  data mining   \n",
       "292   lutterade be a district of geleen and later s...  real mining   \n",
       "\n",
       "                   category  \n",
       "38         Machine learning  \n",
       "165  Data analysis software  \n",
       "170  Data analysis software  \n",
       "127        Machine learning  \n",
       "292                     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at what's inside.  We have a document id (docid), title (from Wikipedia)\n",
    "# the text, the label (one of: 'real mining' or 'data mining'), and a category column\n",
    "# which you can ignore for now (it has the Wikipedia category for just the data mining articles)\n",
    "\n",
    "miningdf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' matlab ( matrix laboratory ) be a multi - paradigm numerical computing environment and proprietary programming language develop by mathworks . matlab allow matrix manipulation , plot of function and datum , implementation of algorithm , creation of user interface , and interfac with program write in other language , include c , c++ , c # , java , fortran and python . \\n\\n although matlab be intend primarily for numerical computing , an optional toolbox use the mupad symbolic engine , allow access to symbolic computing ability . an additional package , simulink , add graphical multi - domain simulation and model - base design for dynamic and embed system . \\n\\n as of 2018 , matlab have more than 3 million user worldwide . matlab user come from various background of engineering , science , and economic . '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you'll notice that the text is lemmatized. Here's the text for the first entry:\n",
    "miningdf.head(1).text.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a82073a71f5e62877e6f77691c35b1ae",
     "grade": false,
     "grade_id": "cell-b9871f6c682c6fcd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will be using the [scattertext](https://github.com/JasonKessler/scattertext) library to create, analyze and position the terms. We encourage you to take a look at all the features of scattertext. It has a lot of \"knobs\" to control the analysis. It will also create a very fancy Web-based, interactive visualization for you if you want. For our initial experiment, we're going to start simple. We simply want to plots terms based on how common they are in 'data mining' and in 'real mining.' The lower-left corner will hold uncommon terms for both. The upper right will be terms that  often appear in both domains. A way to think of this is that terms on the diagonal (slope 1) appear equally in both domains. The other two corners are the outliers--these are terms that are either more common for data or real mining.  Here's a screenshot of what we'll get:\n",
    "\n",
    "![\"scattertext\"](assets/scattertext_small.png)\n",
    "\n",
    "[Click here](assets/scattertext.png) for a larger image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84b77eb79d505d68907b298d857bac01",
     "grade": false,
     "grade_id": "cell-24f7e1b5c120bfe0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We're going to run the analysis for you and have you generate the visualization. Once you get the first version working, you can play with the options to see how they impact the analysis/visualization. In particular, you might want to change the term frequency and PMI (pointwise mutual information) thresholds to see what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the scattertext analysis pipeline to the text, this will create a new column called parse\n",
    "miningdf = miningdf.assign(\n",
    "    parse=lambda df: df.text.apply(st.whitespace_nlp_with_sentences)\n",
    ")\n",
    "\n",
    "# create a \"corpus\" object\n",
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    # use the miningdf as input. The category col is \"label\" and the parsed data is in \"parse\"\n",
    "    miningdf, category_col='label', parsed_col='parse'\n",
    "    # the unigram corpus means we want single words (there's another version that throws out stopwords)\n",
    "    # the association compactor says we want the 2000 most label-associated terms\n",
    ").build().get_unigram_corpus().compact(st.AssociationCompactor(2000))\n",
    "\n",
    "# next, we build the actual visualization \n",
    "scatterdata = st.produce_scattertext_explorer(\n",
    "    corpus,                            # the corpus\n",
    "    category='data mining',            # the \"base\" category\n",
    "    category_name='data mining',       # the label for the category (same in this case)\n",
    "    not_category_name='real mining',   # the label of the other category\n",
    "    minimum_term_frequency=0,          # threshold frequency\n",
    "    pmi_threshold_coefficient=0,       # the PMI threshold\n",
    "    return_data=True,                  # this tells scattertext to return the data rather than saving an HTML page\n",
    "    transform=st.Scalers.dense_rank    # where to place identically ranked terms (on top of each other here)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26d284ec5da60782e68d35a62ac8406a",
     "grade": false,
     "grade_id": "cell-b850158a74fa5abb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "At this point, ```scatterdata``` will contain all kinds of information. For example, ```scatterdata['info']['category_terms']``` will give you the terms most related to the \"category\" (remember, this is data mining). In contrast, you can get the \"real mining\" terms using not_category_terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terms most associated with data mining  ['datum', 'learning', 'algorithm', 'analysis', 'computer', 'data', 'model', 'machine', 'research', 'pattern'] \n",
      "\n",
      "terms most associated with real mining  ['mine', 'town', 'gold', 'south', 'coal', 'locate', 'miner', 'diamond', 'river', 'north']\n"
     ]
    }
   ],
   "source": [
    "print(\"terms most associated with data mining \",scatterdata['info']['category_terms'],\"\\n\")\n",
    "print(\"terms most associated with real mining \",scatterdata['info']['not_category_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e719d3be4caea1fe48d1ac3691ea05ce",
     "grade": false,
     "grade_id": "cell-67dff7c7ad87580f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The more important piece for our visualization purposes is the \"data\" part of scatterdata. This is a list of \"objects,\" one for each term. For example:\n",
    "\n",
    "![\"data example\"](assets/scattertext_content.png)\n",
    "\n",
    "This is the first item in the data list. There are a number of fields here. You can look at the documentation for scattertext for the details. The only items we care about right now will be ```x```, ```y```, ```term```, and ```s```. These respectively tell us the x/y coordinate for the term, the term itself, and the \"distance\" of the term from the central line (slope 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 0.0,\n",
       " 'y': 0.13265306122448978,\n",
       " 'ox': 0.0,\n",
       " 'oy': 0.13265306122448978,\n",
       " 'term': 'matlab',\n",
       " 'cat25k': 15,\n",
       " 'ncat25k': 0,\n",
       " 'neut25k': 0,\n",
       " 'neut': 0,\n",
       " 'extra25k': 0,\n",
       " 'extra': 0,\n",
       " 'cat': 13,\n",
       " 'ncat': 0,\n",
       " 's': 0.8930722891566265,\n",
       " 'os': 0.12921901946292189,\n",
       " 'bg': 1.1352105640948616e-05}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatterdata['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb0ad3cc6900e7fd3fda52281a73e734",
     "grade": false,
     "grade_id": "cell-5e4933e0a6bb891a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We would like for you to use this data to generate a visualization as in the example above. You're welcome to try to make it fancier, but consider this the minimum solution (notice the tooltips and colors). \n",
    "\n",
    "Here's a *zoomed in* version just to show off the interactions:\n",
    "\n",
    "![\"scattertext example\"](assets/interactive_scatter.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d37d9ef17b384fca50661125e46f581",
     "grade": true,
     "grade_id": "cell-187c23a630244666",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# add your solution here\n",
    "\n",
    "# ...\n",
    "\n",
    "def genScattertext():\n",
    "    # this function should return an Altair chart as specified above\n",
    "    \n",
    "    toret = None   # alt.Chart...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return(toret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your code above works correctly, this should generate the plot\n",
    "genScattertext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc39c67049c907070b6d09147b33d00a",
     "grade": false,
     "grade_id": "cell-51609ecddabf3a93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "### Problem 2.1 -- Implementation (70 points)\n",
    "For this problem, we would like for you to build a visual query system using tilebars! You will need to build a function that returns an Altair visualization. It will take as input a query (text string), an option to normalize the data or not (A boolean True or False), and a string indicating the sort order--\"title\" (or \"name\") and \"score\". Here's a pretty bad implementation:\n",
    "\n",
    "![\"tilebar example\"](assets/tilebar.gif)\n",
    "\n",
    "### Important: This example implementation isn't a great one. We expect you to use your skills to build something better. Simply replicating this example will not get you full credit.\n",
    "\n",
    "You are welcome to come up with your own style, add interactivity, decide how to normalize and score, the data, etc. This problem is very open ended. If you don't remember how a tilebar is created, now is a good time to go back to the lecture and watch the video (or go to the [source](https://people.ischool.berkeley.edu/~hearst/research/tilebars.html)).\n",
    "\n",
    "Before we get started, let's load the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're only working with data mining here\n",
    "\n",
    "\n",
    "# lemmatizing these files takes some time on Coursera so we've pre-calculated it for you.\n",
    "# If you want to run this process, uncomment the next three lines of code\n",
    "# We're going to \"cache\" lemmas to speed up some operations\n",
    "# lemmaCache = {}\n",
    "# dataminingdf = generateData('assets/mlarticles.jsonl',lemmaCache)\n",
    "# dataminingdf.to_csv('assets/mlarticles.csv',index=False)\n",
    "\n",
    "dataminingdf = pd.read_csv('assets/mlarticles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>tokencount</th>\n",
       "      <th>category</th>\n",
       "      <th>lineid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>matlab ( matrix laboratory ) be a multi - par...</td>\n",
       "      <td>64</td>\n",
       "      <td>Data mining and machine learning software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>although matlab be intend primarily for numer...</td>\n",
       "      <td>48</td>\n",
       "      <td>Data mining and machine learning software</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>as of 2018 , matlab have more than 3 million ...</td>\n",
       "      <td>27</td>\n",
       "      <td>Data mining and machine learning software</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>raymond kurzweil ( ; bear february 12 , 1948 ...</td>\n",
       "      <td>105</td>\n",
       "      <td>Machine learning researchers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>kurzweil receive the 1999 national medal of t...</td>\n",
       "      <td>141</td>\n",
       "      <td>Machine learning researchers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid         title                                               text  \\\n",
       "0      0        MATLAB   matlab ( matrix laboratory ) be a multi - par...   \n",
       "1      0        MATLAB   although matlab be intend primarily for numer...   \n",
       "2      0        MATLAB   as of 2018 , matlab have more than 3 million ...   \n",
       "3      1  Ray Kurzweil   raymond kurzweil ( ; bear february 12 , 1948 ...   \n",
       "4      1  Ray Kurzweil   kurzweil receive the 1999 national medal of t...   \n",
       "\n",
       "   tokencount                                   category  lineid  \n",
       "0          64  Data mining and machine learning software       0  \n",
       "1          48  Data mining and machine learning software       1  \n",
       "2          27  Data mining and machine learning software       2  \n",
       "3         105               Machine learning researchers       0  \n",
       "4         141               Machine learning researchers       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the first few lines\n",
    "dataminingdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1efe486b331e27e6484c9101033c3e4",
     "grade": false,
     "grade_id": "cell-5498c6547822cdbd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What you see above is a row for every document and every \"line.\"  In pre-processing the top section of each Wikipedia article for you. We have taken each paragraph and made it into a new line. For example, the [MATLAB](https://en.wikipedia.org/wiki/MATLAB) article has 3 lines. The frame has a document id (docid), title, line id (lineid -- based on the order the line appears), text (the text of the line), tokencount (the number of words in that line), and the category of the article (which you can use if you want)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9b1aed6e5a25b3124c258a06cd1c87a",
     "grade": false,
     "grade_id": "cell-e3fa74f5bb3e9f80",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "At this point we're going to start implementing the ```drawTilebars``` function.\n",
    "\n",
    "As we mentioned above, everything outside of the basic functions and tilebar encoding is fair game. You can decide how to rank documents (do you want to do it based on whether the matches are in the same line? whether there are many matches throughout the article?). You can also decide how you want to implement normalization on the tilebars themselves (by tokens in the line? by the maximum times the term appears in the document? the maximum time it appears in all documents?). Here's a static screenshot of our tilebars for \"clustering techniques\" normalized with score based ordering:\n",
    "\n",
    "![\"tilebar example\"](assets/clustering_technique.png)\n",
    "\n",
    "\n",
    "\n",
    "Some hints/ground rules (***read before you start***):\n",
    "* ***Again, this particular version is NOT a good version, please don't simply replicate it.***\n",
    "* We would like results to be *conjunctions* (i.e., we only want results to show those documents that match *all* search results: basically \"ands). You can *optionally* implement disjunctions (i.e., \"ors\") and modify the interface to support that. You can extend the widget/function to support this if you like.\n",
    "* Decide what comparisons need to be enabled by tilebars for them to work. Figure out how those can be *expressed* in the visualization and then made *effective*. There are some very simple things that will take our bad example and make it better. You should go back to the video/other materials. We will expect that *at least* satisfy the key tasks of the original tilebar implementation but you can add your own.\n",
    "* We will consider your design choices in your grade. How it performs will matter, but so will how it looks. \n",
    "* Make sure that sort by score does something reasonable. Think about what you would expect to be on top when you search for 'cluster analysis' (for example)\n",
    "* Test, test, test - small queries, big queries, queries with no matches, etc\n",
    "* Your solution should be performant. We should not be waiting more than a few seconds for the vis to show up.\n",
    "* Take a look at some of the pandas features for text analysis. For example, for a row in our dataframe, you can get the count of the number of times a specific token appears by doing ```row['text'].count(' ' + term + ' ')```\n",
    "* You likely want to calculate two things--one is a dataframe describing your tilebar information, the other is some kind of document order. If you're clever, you can do it all at once. A less efficient solution might require two passes.\n",
    "* Think about what you need to know in order to encode the \"cell\" of the tilebar. Your dataframe should contain that data.\n",
    "* Consider the look and feel of your solution. We will be considering the aesthetic choices you are making. \n",
    "* Think through how to build the \"small multiples\" here. You can use combinations of concatenation, faceting, and repeated charts. You'll likely need to play with a few solutions to get the look you're happy with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e2adda8f3c5972e3fddac7e989e6c1a",
     "grade": true,
     "grade_id": "cell-7ae43d9e0f6a804a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def drawTilebars(query,normalized=False,sortby='title'):\n",
    "    # this function takes \n",
    "    # query: a string query\n",
    "    # normalized: an argument about whether to normalize the tilebar (True or False)\n",
    "    #   if false, the the color of the tile should map to the count\n",
    "    #   if true, you should decide how you want to normalize (by the max count overall? max count in article?)\n",
    "    # sortby: a string of either \"title\" or \"score\"\n",
    "    #   if title, the tilebars should be returned based on alphabetical order of the articles\n",
    "    #   if score, you can decide how you want to rank the articles\n",
    "    # the function returns: an altair chart\n",
    "    print(\"the lemmatized query terms are: \",lemmatize(query))\n",
    "    print(\"nomalized is \",normalized)\n",
    "    print(\"I will sort by\", sortby)\n",
    "    return(alt.Chart(dataminingdf).mark_point())\n",
    "    \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9421e56d7a5a82a0cb85b20ce2a57b3",
     "grade": false,
     "grade_id": "cell-4eeb0e4261e55e16",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "If you built your solution correctly, you should be able to simply run the code below. Note that we don't use Altair interactivity because we don't know how you chose to implement your solution. The visualization will likely flicker as you recalculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output()\n",
    "from IPython.display import display\n",
    "\n",
    "lastquery = \"\"\n",
    "lastsort = \"\"\n",
    "lastnorm = \"\"\n",
    "\n",
    "\n",
    "def clicked(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        _norm = True\n",
    "        _sortby = 'title'\n",
    "        _query = querybox.value\n",
    "        \n",
    "        if (normalizedradio.value == \"false\"):\n",
    "            _norm = False\n",
    "            \n",
    "        if (sortradio.value == 'score'):\n",
    "            _sortby = 'score'\n",
    "            \n",
    "        if (_query == \"\"):\n",
    "            print(\"please enter a query\")\n",
    "        else:\n",
    "            drawTilebars(_query,normalized=_norm,sortby=_sortby).display()\n",
    "\n",
    "\n",
    "querybox = widgets.Text(description='Query:')\n",
    "searchbutton = widgets.Button(description=\"Search\")\n",
    "normalizedradio = widgets.RadioButtons(description=\"Normalized?\",options=['true', 'false'])\n",
    "sortradio = widgets.RadioButtons(description=\"Sort by\",options=['title', 'score'])\n",
    "\n",
    "searchbutton.on_click(clicked)\n",
    "normalizedradio.observe(clicked, names=['value'])\n",
    "sortradio.observe(clicked, names=['value'])\n",
    "\n",
    "list_widgets = [widgets.VBox([widgets.HBox([querybox,searchbutton]),\n",
    "                              widgets.HBox([normalizedradio,sortradio])])]\n",
    "accordion = widgets.Accordion(children=list_widgets)\n",
    "accordion.set_title(0,\"Search Controls\")\n",
    "display(accordion,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7abc3f2418cfe4fbe132bc732b5e56a4",
     "grade": false,
     "grade_id": "cell-75ef21e646c2f59f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 2.2 What did you do?  (10 points)\n",
    "\n",
    "Please detail why you made your design decisions. Again, we want you to improve on our less-than-optimal implementation of tilebars. You should reflect on how well you are meeting each of the objectives of tilebars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your answer here"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_information_visualization_ii_v1_assignment4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
